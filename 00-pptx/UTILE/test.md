
# 1 
- On consid√®re la Q-table suivante :

```
+----+--------+--------+------+-------+
| Q  | gauche | droite |  haut | bas  |
+----+--------+--------+------+-------+
| S1 |  -0.5  |   1    |  2.1 |  1.3  |
+----+--------+--------+------+-------+
| S2 |   0.5  |  0.75  | -0.5 |  1.5  |
+----+--------+--------+------+-------+
| S6 |  -1.2  |   1.2  |  0.7 |  1.7  |
+----+--------+--------+------+-------+
```

# 2

- On consid√®re l'environnement suivant **Grid World** :
```
+----+----+----+
| -1 | -1 | -1 |
+----+----+----+
| -1 | -1 | -1 |
+----+----+----+
| -1 | -10| +10|
+----+----+----+
```

# 3
- Nous voulons que l'agent apprenne la politique cible.
- Dans chaque image, le robot (ü§ñ) repr√©sente l'agent, les fl√®ches indiquent les mouvements possibles ou choisis, 


```
+------+----+----+----+
| ü§ñ  | -1 | -1 | -1 |
+------+----+----+----+
| -1   | -1 | -1 | -1 |
+------+----+----+----+
| -1   | -10| +10| -1 |
+------+----+----+----+
```

- Le robot est repr√©sent√© par le symbole ü§ñ en haut √† gauche. 
- Chaque cellule de la grille correspond √† une r√©compense ou une p√©nalit√©, avec -10 et +10 comme objectifs importants.




# 4

### Le rebot est initialement dans l'√©tat S1

```
+------+----+----+----+
| ü§ñ S1 | -1 | -1 | -1 |
+------+----+----+----+
| -1   | -1 | -1 | -1 |
+------+----+----+----+
| -1   | -10| +10| -1 |
+------+----+----+----+

L'agent prend une d√©cision bas√©e sur une politique de comportement.
```

# 5
###  L'agent peut se d√©placer vers la droite ou vers le bas

```
+---------+----+----+----+
| ü§ñ S1 ‚Üí | -1 | -1 | -1 |
+---‚Üì-----+----+----+----+
|   -1    | -1 | -1 | -1 |
+---------+----+----+----+
|   -1    | -10| +10| -1 |
+---------+----+----+----+
```


# 6

### L'agent prend la d√©cision de se d√©placer vers la droite.

```
+------+----+----+----+
|ü§ñ S1|‚Üí -1 (S2) | -1 | -1 |
+------+----+----+----+
| -1   | -1 | -1 | -1 |
+------+----+----+----+
| -1   | -10| +10| -1 |
+------+----+----+----+


```


#7 Question

EN  utilisant les √©quations de bellman comme vu en classe , mettre √† jour la Q-table pour le Q(s1, right) qui est initalement √† 1

```
+----+--------+--------+------+-------+
| Q  | gauche | droite |  haut | bas  |
+----+--------+--------+------+-------+
| S1 |  -0.5  |   ?    |  2.1 |  1.3  |
+----+--------+--------+------+-------+
| S2 |   0.5  |  0.75  | -0.5 |  1.5  |
+----+--------+--------+------+-------+
| S6 |  -1.2  |   1.2  |  0.7 |  1.7  |
+----+--------+--------+------+-------+
```
