# **Partie-01 : Questions Directes**


1. *Définissez la méthode de Monte Carlo dans le contexte de l'apprentissage par renforcement.*
2. *Quelle est la différence entre la méthode Every-Visit et la méthode First-Visit pour estimer la fonction de valeur d’un état ?*
3. *Expliquez les étapes du processus de prédiction de Monte Carlo pour estimer la valeur d'un état.*
4. *Qu'est-ce que la politique epsilon-greedy et comment aide-t-elle à équilibrer exploration et exploitation ?*
5. *Quelle est l'équation de mise à jour de la fonction de valeur pour la méthode Every-Visit ?*

---

# **Partie-02 : Questions de Réflexion**


1. *Expliquez en quoi l'apprentissage hors politique diffère de l'apprentissage sur politique et pourquoi l'échantillonnage d'importance est utilisé.*
2. *Quel est le rôle du taux d'apprentissage (alpha) dans la mise à jour de la fonction de valeur d'action (Q) lors d'un contrôle Monte Carlo hors politique ?*
3. **Comment le choix de la valeur de $\epsilon$ influence-t-il le comportement de la politique epsilon-greedy ?**
4. **Pourquoi les méthodes de Monte Carlo nécessitent-elles l’observation d’épisodes entiers ?**
5. **Dans l’algorithme de contrôle Monte Carlo (sur politique), comment la politique optimale est-elle obtenue à partir de $Q(s, a)$ ?**
