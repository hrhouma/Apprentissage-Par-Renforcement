# **Partie-01 : Questions Directes**


1. *Définissez la méthode de Monte Carlo dans le contexte de l'apprentissage par renforcement.*
2. *Quelle est la différence entre la méthode Every-Visit et la méthode First-Visit pour estimer la fonction de valeur d’un état ?*
3. *Expliquez les étapes du processus de prédiction de Monte Carlo pour estimer la valeur d'un état.*
4. *Qu'est-ce que la politique epsilon-greedy et comment aide-t-elle à équilibrer exploration et exploitation ?*
5. *Quelle est l'équation de mise à jour de la fonction de valeur pour la méthode Every-Visit ?*

---

# **Partie-02 : Questions de Réflexion**


1. *Expliquez en quoi l'apprentissage hors politique diffère de l'apprentissage sur politique et pourquoi l'échantillonnage d'importance est utilisé.*
2. *Quel est le rôle du taux d'apprentissage (alpha) dans la mise à jour de la fonction de valeur d'action (Q) lors d'un contrôle Monte Carlo hors politique ?*
3. *Comment le choix de la valeur de $\epsilon$ influence-t-il le comportement de la politique epsilon-greedy ?*
4. *Pourquoi les méthodes de Monte Carlo nécessitent-elles l’observation d’épisodes entiers ?*
5. *Dans l’algorithme de contrôle Monte Carlo (sur politique), comment la politique optimale est-elle obtenue à partir de $Q(s, a)$ ?*






















Voici les questions corrigées sans les caractères # :

**Partie-01 : Questions Directes**

1. Définissez la méthode de Monte Carlo dans le contexte de l'apprentissage par renforcement.

2. Quelle est la différence entre la méthode Every-Visit et la méthode First-Visit pour estimer la fonction de valeur d'un état ?

3. Expliquez les étapes du processus de prédiction de Monte Carlo pour estimer la valeur d'un état.

4. Qu'est-ce que la politique epsilon-greedy et comment aide-t-elle à équilibrer exploration et exploitation ?

5. Quelle est l'équation de mise à jour de la fonction de valeur pour la méthode Every-Visit ?

**Partie-02 : Questions de Réflexion**

1. Expliquez en quoi l'apprentissage hors politique diffère de l'apprentissage sur politique et pourquoi l'échantillonnage d'importance est utilisé.

2. Quel est le rôle du taux d'apprentissage (alpha) dans la mise à jour de la fonction de valeur d'action (Q) lors d'un contrôle Monte Carlo hors politique ?

3. Comment le choix de la valeur de $\epsilon$ influence-t-il le comportement de la politique epsilon-greedy ?

4. Pourquoi les méthodes de Monte Carlo nécessitent-elles l'observation d'épisodes entiers ?

5. Dans l'algorithme de contrôle Monte Carlo (sur politique), comment la politique optimale est-elle obtenue à partir de $Q(s, a)$ ?

Citations:
[1] https://notesonai.com/monte-carlo+rl+methods
[2] http://incompleteideas.net/book/ebook/node50.html
[3] https://www.andrew.cmu.edu/course/10-403/slides/S19_lecture4_MC.pdf
[4] https://www.ericsson.com/en/blog/2023/12/online-and-offline-reinforcement-learning-what-are-they-and-how-do-they-compare
[5] https://core-robotics.gatech.edu/2022/02/28/bootcamp-summer-2020-week-4-on-policy-vs-off-policy-reinforcement-learning/
[6] https://nn.cs.utexas.edu
[7] https://gibberblot.github.io/rl-notes/single-agent/temporal-difference-learning.html
[8] https://stackoverflow.com/questions/53198503/epsilon-and-learning-rate-decay-in-epsilon-greedy-q-learning/53202849
[9] https://lrscy.github.io/2020/07/09/Coursera-Reinforcement-Learning-Course2-Week2-Notes/
[10] https://cwkx.github.io/data/teaching/dl-and-rl/rl-lecture5.pdf
[11] https://www.reddit.com/r/reinforcementlearning/comments/ypggad/first_visit_and_every_visit_monte_carlo_methods/
[12] https://towardsdatascience.com/reinforcement-learning-part-4-monte-carlo-control-ae0a7f29920b
[13] https://www.baeldung.com/cs/epsilon-greedy-q-learning
[14] https://towardsdatascience.com/reinforcement-learning-part-3-monte-carlo-methods-7ce2828a1fdb
[15] https://stackoverflow.com/questions/52832180/first-visit-vs-every-visit-monte-carlo
