# Plan de la séance

-----------------------------------------------------------------------
# Partie 1 - rappel du processus de Décision de Markov (MDP)
-----------------------------------------------------------------------

# Composantes des MDP :
- **États (S)** : Représentent les différentes situations possibles dans lesquelles un agent peut se trouver.
- **Actions (A)** : Les différentes actions que l'agent peut entreprendre dans un état donné.
- **Transitions (P(s'|s,a) ou T(s,a,s'))** : La probabilité de passer d'un état à un autre, en fonction de l'action entreprise.
- **Récompenses (R(s,a,s') et facteur de réduction γ)** : Les récompenses obtenues par l'agent lorsqu'il effectue une transition entre états après avoir pris une action.
- **État de départ (s₀)** : L'état initial à partir duquel le processus commence.

# Quantités importantes :
- **Politique** : Une stratégie ou une fonction qui associe à chaque état une action à entreprendre.
- **Utilité** : La somme des récompenses actualisées, où les récompenses futures sont pondérées par le facteur de réduction (γ).

-----------------------------------------------------------------------
# Partie 2 - offline vs online learning
-----------------------------------------------------------------------



-----------------------------------------------------------------------
# Partie 3 - Équation de Bellman 
-----------------------------------------------------------------------



-----------------------------------------------------------------------
# Partie 4 - Démonstration 1
-----------------------------------------------------------------------

-----------------------------------------------------------------------
# Partie 5 - (Justification de la démo 1 et exercice): Comment utiliser l'équation de Bellman dans l'Apprentissage par Renforcement
-----------------------------------------------------------------------


-----------------------------------------------------------------------
# Partie 6 - Q-Learning
-----------------------------------------------------------------------




-----------------------------------------------------------------------
# Partie 7 - Démonstration 2
-----------------------------------------------------------------------


- Comment utiliser l'Équation de Bellman dans l'Apprentissage par Renforcement 
