
# Explications supplémentaires

L'algorithme Monte Carlo pour la prédiction de politique est un outil puissant en apprentissage par renforcement. Dans cet exemple, nous appliquons la prédiction Monte Carlo pour évaluer une politique simple dans un jeu de Blackjack. Ce projet vous aidera à comprendre comment fonctionnent les simulations par épisodes, la mise à jour des valeurs et la visualisation en trois dimensions des fonctions de valeur.

### Les règles de base du Blackjack
Dans le Blackjack :
- Le but du jeu est de faire une somme de cartes la plus proche possible de 21, sans dépasser ce nombre.
- Les cartes J, K, et Q ont une valeur de 10, les cartes de 2 à 10 ont leur valeur nominale, et l'as peut valoir soit 1, soit 11, selon la situation (on appelle cela un "usable ace" lorsque l'as vaut 11).
- Le joueur peut "hit" (demander une nouvelle carte) ou "stick" (s'arrêter et ne plus demander de carte).

### Étape 1 : Initialisation de l'environnement
Nous utilisons le package `gym` pour créer l'environnement de Blackjack dans lequel nous allons effectuer nos simulations. 

```python
import torch
import gym

env = gym.make('Blackjack-v0')
```

### Étape 2 : Fonction pour exécuter un épisode
L'algorithme nécessite d'exécuter plusieurs épisodes pour évaluer la politique. La fonction suivante exécute un épisode complet du jeu de Blackjack avec une politique simple : le joueur tire une carte (hit) tant que sa somme de points est inférieure à un score seuil (`hold_score`), et s'arrête (stick) autrement.

```python
def run_episode(env, hold_score):
     state = env.reset()
     rewards = []
     states = [state]
     is_done = False
     while not is_done:
         action = 1 if state[0] < hold_score else 0  # hit si le score est inférieur au seuil
         state, reward, is_done, info = env.step(action)
         states.append(state)
         rewards.append(reward)
         if is_done:
             break
     return states, rewards
```

### Étape 3 : Prédiction Monte Carlo First-Visit
La prédiction Monte Carlo consiste à calculer la fonction de valeur de chaque état en moyenne sur plusieurs épisodes. Nous effectuons cela en prenant en compte uniquement la première visite de chaque état dans un épisode donné (méthode First-Visit).

```python
from collections import defaultdict

def mc_prediction_first_visit(env, hold_score, gamma, n_episode):
     V = defaultdict(float)
     N = defaultdict(int)
     for episode in range(n_episode):
         states_t, rewards_t = run_episode(env, hold_score)
         return_t = 0
         G = {}
         for state_t, reward_t in zip(states_t[1::-1], rewards_t[::-1]):
             return_t = gamma * return_t + reward_t
             G[state_t] = return_t
         for state, return_t in G.items():
             if state[0] <= 21:  # Ignorer les états où le joueur dépasse 21
                 V[state] += return_t
                 N[state] += 1
     for state in V:
         V[state] = V[state] / N[state]
     return V

# Paramètres de la simulation
hold_score = 18
gamma = 1
n_episode = 500000

# Calcul de la fonction de valeur avec Monte Carlo
value = mc_prediction_first_visit(env, hold_score, gamma, n_episode)

print('The value function calculated by first-visit MC prediction:\n', value)
print('Number of states:', len(value))
```

### Étape 4 : Visualisation des fonctions de valeur
L'étape suivante consiste à visualiser les fonctions de valeur calculées. La fonction de valeur dépend de l'état du joueur (somme des cartes), de la carte visible du croupier, et de la présence d'un "usable ace". Nous utilisons `matplotlib` pour créer une visualisation 3D de ces valeurs.

```python
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import matplotlib

def plot_surface(X, Y, Z, title):
     fig = plt.figure(figsize=(20, 10))
     ax = fig.add_subplot(111, projection='3d')
     surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=matplotlib.cm.coolwarm, vmin=-1.0, vmax=1.0)
     ax.set_xlabel('Player Sum')
     ax.set_ylabel('Dealer Showing')
     ax.set_zlabel('Value')
     ax.set_title(title)
     ax.view_init(ax.elev, -120)
     fig.colorbar(surf)
     plt.show()

def plot_blackjack_value(V):
     player_sum_range = range(12, 22)
     dealer_show_range = range(1, 11)
     X, Y = torch.meshgrid([torch.tensor(player_sum_range), torch.tensor(dealer_show_range)])
     values_to_plot = torch.zeros((len(player_sum_range), len(dealer_show_range), 2))
     for i, player in enumerate(player_sum_range):
         for j, dealer in enumerate(dealer_show_range):
             for k, ace in enumerate([False, True]):
                 values_to_plot[i, j, k] = V[(player, dealer, ace)]
     plot_surface(X, Y, values_to_plot[:,:,0].numpy(), "Blackjack Value Function Without Usable Ace")
     plot_surface(X, Y, values_to_plot[:,:,1].numpy(), "Blackjack Value Function With Usable Ace")

plot_blackjack_value(value)
```

### Explications finales
1. **Exécution des épisodes** : L'algorithme simule plusieurs parties (500 000 dans notre exemple) en suivant une politique donnée (ici, le joueur s'arrête dès qu'il a au moins 18 points).
2. **Calcul de la fonction de valeur** : Pour chaque épisode, la fonction de valeur est calculée en moyennant les retours pour chaque état visité lors de la première visite.
3. **Visualisation** : La fonction de valeur est visualisée en trois dimensions, permettant de comparer la valeur d'un état en fonction de la somme des cartes du joueur, de la carte visible du croupier, et de la présence d'un "usable ace".

